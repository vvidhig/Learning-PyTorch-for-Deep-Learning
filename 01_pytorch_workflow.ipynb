{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6053f72b-8f2c-4dc0-bb6d-3a64e0bcf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn #nn contains all of PyTorch's building blocks for neural networks\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d45e078-316a-4515-8add-5b5eab57b88c",
   "metadata": {},
   "source": [
    "## 1. Data Preparing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b233cb-0c05-47d0-9a60-da6a184d812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create known parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "#create data\n",
    "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n",
    "Y = weight*X + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e83bfde-4b07-4468-b2a7-b4f180eb1980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10], Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd67a1-a5b4-4031-84fe-629c8e688cdc",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d4a081-79ca-491d-906b-2a8e8df3ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X)) #80% of data is used for training and the rest 20% for testing\n",
    "Xtrain = X[:train_split]\n",
    "Ytrain = Y[:train_split]\n",
    "Xtest = X[train_split:]\n",
    "Ytest = Y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c010bd39-1538-48a8-a87d-745fec03c653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xtrain), len(Ytrain), len(Xtest), len(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9acaa8-ef9a-45a4-b8dc-30e6acff1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=Xtrain, \n",
    "                     train_labels=Ytrain, \n",
    "                     test_data=Xtest, \n",
    "                     test_labels=Ytest, \n",
    "                     predictions=None):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "  \n",
    "  # Plot test data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    # Plot the predictions in red (predictions were made on the test data)\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "  # Show the legend\n",
    "  plt.legend(prop={\"size\": 14});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10df327-d86c-4d25-a988-fe5e6825ae9e",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401e1019-56de-426c-b402-db3e1a4e33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Linear Regression class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "252a14dd-819a-4cd0-91c3-02098b31d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module): #nn.module is the base class for all neural network modules\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad = True, dtype = torch.float64))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype = torch.float64))\n",
    "\n",
    "    #Forward method to define the complutation in a model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights*x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf55253-89a2-4c38-9694-7021bcdb5866",
   "metadata": {},
   "source": [
    "nn.Module - contains the larger building blocks (layers)\n",
    "\n",
    "nn.Parameter - contains the smaller parameters like weights and biases (put these together to make nn.Module(s))\n",
    "\n",
    "forward() - tells the larger blocks how to make calculations on inputs (tensors full of data) within nn.Module(s)\n",
    "\n",
    "torch.optim - contains optimization methods on how to improve the parameters within nn.Parameter to better represent input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e3f50-4f7f-4b6f-9417-b08fe9459ddd",
   "metadata": {},
   "source": [
    "## Checking the contents of the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c65a01-74e3-4681-b49a-8875a2efac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialzied\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model (this is a subclass of nn.Module that contains nn.Parameter(s)\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check the nn.Parameter(s) within the nn.Module subclass we created\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbe231b-24f2-432a-b98e-44e266b95fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367], dtype=torch.float64)),\n",
       "             ('bias', tensor([0.1288], dtype=torch.float64))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159bc610-ad21-46ba-9dda-a0b508b11ed8",
   "metadata": {},
   "source": [
    "## Making predictions using torch.inference_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c28cb7-dab6-44ae-9641-2313d131ba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251],\n",
       "        [0.4318],\n",
       "        [0.4386],\n",
       "        [0.4453],\n",
       "        [0.4520],\n",
       "        [0.4588]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(Xtest)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8894f1-5a14-4f19-b741-8e12657c20a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4618],\n",
       "        [0.4691],\n",
       "        [0.4764],\n",
       "        [0.4836],\n",
       "        [0.4909],\n",
       "        [0.4982],\n",
       "        [0.5054],\n",
       "        [0.5127],\n",
       "        [0.5200],\n",
       "        [0.5272]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest - y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b379d72-5ba7-4103-915d-20baca82b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a loss function\n",
    "loss_fn = nn.L1Loss() #Mean Absolute Error is same as L1 Loss\n",
    "\n",
    "#create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr = 0.01)\n",
    "#params is the target model parameters you'd like to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4654d44-7fc4-4fbd-babf-f5cbfdbbb402",
   "metadata": {},
   "source": [
    "## Creating an optimization loop in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bcd933-f48c-41ba-8fe9-fee637230146",
   "metadata": {},
   "source": [
    "it's now time to create a training loop (and testing loop).\n",
    "\n",
    "The training loop involves the model going through the training data and learning the relationships between the features and labels.\n",
    "\n",
    "The testing loop involves going through the testing data and evaluating how good the patterns are that the model learned on the training data (the model never see's the testing data during training)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8813ce5-e774-429a-9a36-7b83cf22fe69",
   "metadata": {},
   "source": [
    "## PyTorch training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb2df8-71fe-44ce-ba0e-0baebf27050b",
   "metadata": {},
   "source": [
    "\n",
    "1\t**Forward pass**\t-     model(x_train)\n",
    "\n",
    "The model goes through all of the training data once, performing its forward() function calculations.\n",
    "\n",
    "2\t**Calculate the loss**\t -   loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "The model's outputs (predictions) are compared to the ground truth and evaluated to see how wrong they are.\n",
    "\n",
    "3\t**Zero gradients**\t-  optimizer.zero_grad()\n",
    "\n",
    "The optimizers gradients are set to zero (they are accumulated by default) so they can be recalculated for the specific training step.\n",
    "\n",
    "4\t**Perform backpropagation on the loss**  -  loss.backward()\n",
    "\n",
    "Computes the gradient of the loss with respect for every model parameter to be updated (each parameter with requires_grad=True). This is known as backpropagation, hence \"backwards\".\n",
    "\n",
    "5\t**Update the optimizer (gradient descent)**  -  optimizer.step()\n",
    "\n",
    "Update the parameters with requires_grad=True with respect to the loss gradients in order to improve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7379f960-7614-4ada-9f0b-0e75a276226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.31288135683755547 | MAE Test Loss: 0.4810651841540759\n",
      "Epoch: 10 | MAE Train Loss: 0.1976713574739093 | MAE Test Loss: 0.346355184508239\n",
      "Epoch: 20 | MAE Train Loss: 0.08908721056311557 | MAE Test Loss: 0.21729648486064157\n",
      "Epoch: 30 | MAE Train Loss: 0.05314849742260115 | MAE Test Loss: 0.14464008519991425\n",
      "Epoch: 40 | MAE Train Loss: 0.04543793101588776 | MAE Test Loss: 0.11360938544629148\n",
      "Epoch: 50 | MAE Train Loss: 0.041678606478126046 | MAE Test Loss: 0.09919938569279392\n",
      "Epoch: 60 | MAE Train Loss: 0.03818929484512264 | MAE Test Loss: 0.08886628595826254\n",
      "Epoch: 70 | MAE Train Loss: 0.03476085499350197 | MAE Test Loss: 0.08059388621223337\n",
      "Epoch: 80 | MAE Train Loss: 0.031323806993240874 | MAE Test Loss: 0.07232148646620422\n",
      "Epoch: 90 | MAE Train Loss: 0.02788736528831538 | MAE Test Loss: 0.06473598671634251\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 100 #an epoch is one loop through the data\n",
    "epoch_count = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    #set the model to training mode\n",
    "    model_0.train()\n",
    "\n",
    "    #forward pass\n",
    "    y_pred = model_0(Xtrain)\n",
    "\n",
    "    #calculate the loss\n",
    "    loss = loss_fn(y_pred, Ytrain) \n",
    "\n",
    "    #optimize zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #perform backpropagation on the loss with respect to the parameters of the model\n",
    "    loss.backward()\n",
    "\n",
    "    #step the optimizer (perform gradient descent)\n",
    "    optimizer.step()\n",
    "    \n",
    "    model_0.eval() #turns off gradient tracking\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_0(Xtest)\n",
    "        test_loss = loss_fn(test_pred, Ytest.type(torch.float))\n",
    "        if epoch%10==0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy)\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b746bec9-4774-4c06-b812-cc68c6c4e48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.5784], dtype=torch.float64)),\n",
       "             ('bias', tensor([0.3513], dtype=torch.float64))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954e54f6-9be0-4566-805b-d455fb5b98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17fbc618-8e1a-4d57-bf83-3e5eefa4d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('weights', tensor([0.5784], dtype=torch.float64)), ('bias', tensor([0.3513], dtype=torch.float64))])\n",
      "\n",
      "And the original values for weights and bias are:\n",
      "weights: 0.7, bias: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Find our model's learned parameters\n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "print(model_0.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weight}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc99dd7-3e7a-4daf-8d32-8475bd2cc1f2",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2926b689-d549-45f9-aad3-60ed07b22b3f",
   "metadata": {},
   "source": [
    "If you've trained a PyTorch model, chances are you'll want to save it and export it somewhere.\n",
    "\n",
    "As in, you might train it on Google Colab or your local machine with a GPU but you'd like to now export it to some sort of application where others can use it.\n",
    "\n",
    "Or maybe you'd like to save your progress on a model and come back and load it back later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47807194-3d96-40b3-b69a-d7e3ba197190",
   "metadata": {},
   "source": [
    "**torch.save** - Saves a serialized object to disk using Python's pickle utility. Models, tensors and various other Python objects like dictionaries can be saved using torch.save.\n",
    "\n",
    "**torch.load** - Uses pickle's unpickling features to deserialize and load pickled Python object files (like models, tensors or dictionaries) into memory. You can also set which device to load the object to (CPU, GPU etc).\n",
    "\n",
    "**torch.nn.Module.load_state_dict** - Loads a model's parameter dictionary (model.state_dict()) using a saved state_dict() object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a959e2a-a74a-4243-8822-6ddcadc37b80",
   "metadata": {},
   "source": [
    "## Saving a PyTorch model's state_dict()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7a69f78-f7a9-4ea2-a02f-e64b004ef53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('models/01_pytorch_workflow_model_0.pth')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#create Model Directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok = True)\n",
    "\n",
    "#create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "MODEL_SAVE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e7ad261-b6f9-4b32-a331-d046ecb239cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801fa6f8-7432-4141-bba0-82e2b92d23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model state dict\n",
    "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f9732-e2dc-46a9-be95-0897a90a6b5b",
   "metadata": {},
   "source": [
    "## Loading a saved PyTorch model's state_dict()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc0d1089-389c-4549-9a52-447e68ea6d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a new instance of our model (this will be instantiated with random weights)\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "# Load the state_dict of our saved model (this will update the new instance of our model with trained weights)\n",
    "loaded_model_0.load_state_dict(torch.load(f = MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "027a334d-a6a2-4689-a4fd-af341446359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Put the loaded model into evaluation mode\n",
    "loaded_model_0.eval()\n",
    "\n",
    "# 2. Use the inference mode context manager to make predictions\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_model_0(Xtest) # perform a forward pass on the test data with the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "246a3519-f471-4bd5-86d2-5ff51ef36eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred == loaded_model_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "758e573d-804c-4cbc-8747-3116d6d21694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.5784], dtype=torch.float64)),\n",
       "             ('bias', tensor([0.3513], dtype=torch.float64))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_0.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
